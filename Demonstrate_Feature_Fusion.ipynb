{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWhkd4Lb7xKeAilQT5XYjr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhut-ngnn/Practice-Graph_Neural_Network/blob/main/Demonstrate_Feature_Fusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FD2zl4tbDtuX"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CBAM Module\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            # The input channels to this layer should match the channels of the input tensor\n",
        "            nn.Conv2d(channels, channels // reduction, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(channels // reduction, channels, 1, bias=False), # Also adjust output channels here\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Channel Attention\n",
        "        ca = self.channel_attention(x)\n",
        "        x = x * ca\n",
        "\n",
        "        # Spatial Attention\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        sa = self.spatial_attention(torch.cat([avg_out, max_out], dim=1))\n",
        "        x = x * sa\n",
        "        return x\n",
        "\n",
        "class AlexNetCBAM(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNetCBAM, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            CBAM(64),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            CBAM(192),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            CBAM(384),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            CBAM(256),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            CBAM(256),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(f\"Input shape: {x.shape}\")\n",
        "        x = self.features[0](x)\n",
        "        print(f\"After first Conv2d: {x.shape}\")\n",
        "        x = self.features[1](x)\n",
        "        x = self.features[2](x)\n",
        "        print(f\"After first MaxPool2d: {x.shape}\")\n",
        "        x = self.features[3](x)\n",
        "        print(f\"After first CBAM: {x.shape}\")\n",
        "        x = self.features[4](x)\n",
        "        print(f\"After second Conv2d: {x.shape}\")\n",
        "        x = self.features[5](x)\n",
        "        x = self.features[6](x)\n",
        "        print(f\"After second MaxPool2d: {x.shape}\")\n",
        "        x = self.features[7](x)\n",
        "        print(f\"After second CBAM: {x.shape}\")\n",
        "        x = self.features[8](x)\n",
        "        print(f\"After third Conv2d: {x.shape}\")\n",
        "        x = self.features[9](x)\n",
        "        print(f\"After third CBAM: {x.shape}\")\n",
        "        x = self.features[10](x)\n",
        "        print(f\"After fourth Conv2d: {x.shape}\")\n",
        "        x = self.features[11](x)\n",
        "        print(f\"After fourth CBAM: {x.shape}\")\n",
        "        x = self.features[12](x)\n",
        "        print(f\"After fifth Conv2d: {x.shape}\")\n",
        "        x = self.features[13](x)\n",
        "        x = self.features[14](x)\n",
        "        print(f\"After third MaxPool2d: {x.shape}\")\n",
        "        x = self.features[15](x)\n",
        "        print(f\"After fifth CBAM: {x.shape}\")\n",
        "        x = torch.flatten(x, 1)\n",
        "        print(f\"After flatten: {x.shape}\")\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "Wug5SeY8GO_M"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_audio_file(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)  # Load the audio file with its native sampling rate\n",
        "    return y, sr\n",
        "\n",
        "def audio_to_melspectrogram(y, sr, n_mels=128):\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels)\n",
        "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "    return mel_spectrogram_db\n",
        "\n",
        "def extract_mfcc(y, sr, n_mfcc=13, n_mels=128, fmax=8000):\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, n_mels=n_mels, fmax=fmax)\n",
        "    return mfccs\n",
        "\n",
        "def preprocess_mfcc(mfccs):\n",
        "    mfccs = (mfccs - np.mean(mfccs)) / np.std(mfccs)\n",
        "    mfccs = np.expand_dims(mfccs, axis=0)\n",
        "    mfccs = np.expand_dims(mfccs, axis=0)\n",
        "    return torch.tensor(mfccs, dtype=torch.float32)\n",
        "\n",
        "def preprocess_spectrogram(spectrogram):\n",
        "    spectrogram = (spectrogram - np.mean(spectrogram)) / np.std(spectrogram)\n",
        "    spectrogram = np.expand_dims(spectrogram, axis=0)\n",
        "    spectrogram = np.expand_dims(spectrogram, axis=0)\n",
        "    return torch.tensor(spectrogram, dtype=torch.float32)\n",
        "\n",
        "file_path = '/content/Sound_Demo/common_voice_vi_21824030.mp3'\n",
        "y, sr = load_audio_file(file_path)\n",
        "mel_spectrogram_db = audio_to_melspectrogram(y, sr)\n",
        "input_tensor = preprocess_spectrogram(mel_spectrogram_db)\n",
        "model = AlexNetCBAM(num_classes=10)\n",
        "\n",
        "output = model.features(input_tensor)\n",
        "print(output.shape)\n",
        "\n",
        "mfcc = extract_mfcc(y, sr)\n",
        "input_tensor = preprocess_mfcc(mfcc)\n",
        "print(input_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7ROdHgtG7DY",
        "outputId": "aaab818f-1acc-4244-a3ba-b25369e4d1b1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 256, 3, 22])\n",
            "torch.Size([1, 1, 13, 741])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IwrFVTJvI54y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}